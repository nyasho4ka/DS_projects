{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "\n",
    "You have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, you need to develop a model that will pick the right plan. Since youâ€™ve already performed the data preprocessing step, you can move straight to creating the model.\n",
    "\n",
    "Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    features, target = data.drop(columns=['is_ultra']), data['is_ultra']\n",
    "    \n",
    "    features_train, features_test, target_train, target_test = \\\n",
    "        train_test_split(features, target, test_size=0.2)\n",
    "    \n",
    "    features_train, features_valid, target_train, target_valid = \\\n",
    "        train_test_split(features_train, target_train, test_size=0.2)\n",
    "    \n",
    "    return features_train, features_valid, features_test, \\\n",
    "           target_train, target_valid, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_valid, features_test, target_train, target_valid, target_test = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check sizes of samples\n",
    "assert features_train.shape[0] == target_train.shape[0]\n",
    "assert features_valid.shape[0] == target_valid.shape[0]\n",
    "assert features_test.shape[0] == target_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2056 objects for training\n"
     ]
    }
   ],
   "source": [
    "# How much samples do we have for training?\n",
    "print('There are {} objects for training'.format(features_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train several models on the train set and check their perfomance on valid data set.\n",
    "\n",
    "Then we choose the best model among them and check it on the test set, to see real perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Now we have to choose models that we will train\n",
    "   It will be:\n",
    "       1. LogisticRegression\n",
    "       2. DecisionTreeClassfifier (max_depth = (1, 10))\n",
    "       3. RandomForestClassifiier (n_estimators = (10, 100, 10) and max_depth = (1, 10))\n",
    "\"\"\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def choose_best_model(features_train, target_train, features_valid, target_valid):\n",
    "    # At first let's create models\n",
    "    models = list()\n",
    "    models.append(get_logistic_regression_model())\n",
    "    models.append(get_decision_tree_model())\n",
    "    models.append(get_random_forest_model())\n",
    "    # Now let's train it\n",
    "    for model in models:\n",
    "        train_model(model, features_train, target_train)\n",
    "    # Now let's choose the best among every type\n",
    "    best_models = list()\n",
    "    for model in models:\n",
    "        best_models.append(get_best_model(model))\n",
    "    \n",
    "    # Now let's choose the best from these three models\n",
    "    return max(best_models, key=lambda model: accuracy_score(model.predict(features_valid), target_valid))\n",
    "    \n",
    "    \n",
    "def get_logistic_regression_model():\n",
    "    return LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "\n",
    "def get_decision_tree_model():\n",
    "    decision_tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    decision_tree_params = {'max_depth': range(1, 11)}\n",
    "    return GridSearchCV(decision_tree, decision_tree_params)\n",
    "\n",
    "\n",
    "def get_random_forest_model():\n",
    "    random_forest = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "    random_forest_params = {'n_estimators': range(10, 101, 10), 'max_depth': range(1, 11)}\n",
    "    return GridSearchCV(random_forest, random_forest_params)\n",
    "\n",
    "\n",
    "def train_model(model, features_train, target_train):\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "\n",
    "def get_best_model(model):\n",
    "    if not hasattr(model, 'best_estimator_'):\n",
    "        return model\n",
    "    return model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "best_model = choose_best_model(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=70,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best model has 70 estimators (70 trees) and max depth equals to 10. Let's check it's accuracy score on train, valid and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Check the model quality using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_on_sets(best_model, features, target):\n",
    "    features_train = features['train']\n",
    "    predictions_train = best_model.predict(features_train)\n",
    "    target_train = target['train']\n",
    "    train_accuracy = accuracy_score(target_train, predictions_train)\n",
    "    \n",
    "    features_valid = features['valid']\n",
    "    predictions_valid = best_model.predict(features_valid)\n",
    "    target_valid = target['valid']\n",
    "    valid_accuracy = accuracy_score(target_valid, predictions_valid)\n",
    "    \n",
    "    features_test = features['test']\n",
    "    predictions_test = best_model.predict(features_test)\n",
    "    target_test = target['test']\n",
    "    test_accuracy = accuracy_score(target_test, predictions_test)\n",
    "    \n",
    "    return train_accuracy, valid_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {\n",
    "    'train': features_train,\n",
    "    'valid': features_valid,\n",
    "    'test': features_test\n",
    "}\n",
    "\n",
    "target_dict = {\n",
    "    'train': target_train,\n",
    "    'valid': target_valid,\n",
    "    'test': target_test\n",
    "}\n",
    "\n",
    "train_accuracy, valid_accuracy, test_accuracy = get_accuracy_on_sets(best_model, features_dict, target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8959143968871596\n",
      "Valid accuracy: 0.8058252427184466\n",
      "Test Accuracy:0.776049766718507\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy: {}\\nValid accuracy: {}\\nTest Accuracy:{}'\n",
    "      .format(train_accuracy, valid_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got approximately 0.78 accuracy on the test set! I suppose that we may have a better perfomance if we have more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Model sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suppose that sanity check is a check that model has better perfomance than random classification, or classification just one class (such class that have a majority).\n",
    "\n",
    "Our test accuracy is 0.77 so it's better than random classifier. But let's look at the class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of smart clients: 430\n",
      "The number of ultra clients: 213\n"
     ]
    }
   ],
   "source": [
    "smart_target = (target_test == 0)\n",
    "ultra_target = (target_test == 1)\n",
    "\n",
    "print('The number of smart clients: {}'.format(smart_target.sum()))\n",
    "print('The number of ultra clients: {}'.format(ultra_target.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that the number of smart clients is a twice more than ultra clients. Now let's suppose that our classifier choose 0 for all clients. Let's see it's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of \"smart\" classifier: 0.6687402799377916\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of \"smart\" classifier: {}'.format(smart_target.sum() / target_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that accuracy of the classifier is less than our RandomForestClassifier. It means that our classifier are better than random and better than classifier which choose only major class for all examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We got a classifier with approximately 0.78 accuracy score. It means that we will suggest the right tariff for legacy clients in 78% cases.\n",
    "\n",
    "Also we did sanity check for our model and it's better than random and major class classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
